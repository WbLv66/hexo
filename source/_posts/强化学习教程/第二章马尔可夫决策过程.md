---
title: 第二章马尔可夫决策过程
date: 2025-05-21 17:18:40
# updated:
# tags:
#     - 
categories: 强化学习教程
# keywords:
# description:
top_img: transparent
# comments:
# cover:
# toc:
# toc_number:
# toc_style_simple:
# copyright:
# copyright_author:
# copyright_author_href:
# copyright_url:
# copyright_info:
# mathjax:
# katex:
# aplayer:
# highlight_shrink:
# aside:
# abcjs:
# noticeOutdate:
---

在强化学习中，智能体与化境的交互过程可以通过马尔可夫决策过程来表示，马尔可夫决策过程是强化学习的基本框架

本章首先介绍**马尔可夫过程**（Markov process，MP）以及**马尔科夫奖励过程**（Markov reward process，MRP）。二者比较得到**马尔科夫决策过程**（Markov decision process，MDP）。其次介绍马尔科夫决策过程中的**策略评估**（policy evaluation）。最后介绍马尔科夫决策过程中的控制，分为**策略迭代**（policy iteration）和**价值迭代**（value iteration）

## 1. 马尔可夫过程

### 1.1 马尔可夫性质

**马尔可夫性质**（Markov property）是指未来状态的条件概率分布仅依赖于当前状态。假设$X_0,X_1,\cdots,X_t$构成随机过程，如果具有马尔可夫性质则

$$ p \left( X_{t+1}=x_{t+1} | X_{0:t}=x_{0:t} \right) = p \left( X_{t+1}=x_{t+1} | X_{t} = x_{t} \right) $$

其中，$X_{0:t}$表示变量集合$X_0,X_1,\cdots,X_t$，$x_{0:t}$表示状态序列$x_0,x_1,\cdots,x_t$

马尔可夫性质也可以描述为给定当前状态时，将来的状态与过去状态是条件独立的

> 此处补充随机变量的定义
>
> 随机变量表示随机试验各种结果的实值单值函数，即随机过程的结果到数值的映射
>
> 假设我们有一个抛硬币的随机过程。随机变量$X$将随机过程（掷硬币）的结果（正、反）映射到数值（1、0）

## 马尔可夫链
